from multiprocessing import Pool
import time
import math
from visualization import *
import in_out as io


### fitness landscape

# TODO check during weekend 15-17.02
def generate_LON(A, runs_amount, termination_criterion, kick_strength):  # LON sampling (Algorithm 1 from paper [1])
    T = runs_amount  # number of Chained-LK runs
    I = termination_criterion  # termination criterion of run
    L = set()  # set of local optima
    E = {}  # escape edges

    run_result = {}
    iters = {}
    best_path = None
    best_path_length = math.inf

    pool = Pool()  # for parallel operations
    begin = time.time()
    for s_res, s, iters_, L_, E_ in pool.starmap(CLK, [(I, A, kick_strength) for t in range(T)]):  # starmap - map with multiple args
        L = L | L_  # set union  # TODO probable time losing place
        for k, v in E_.items():  # TODO plateaus?
            if k in E:
                E[k] += v
            else:
                E[k] = v

        if s_res in run_result:  # TODO test
            run_result[s_res] += 1
            iters[s_res] += iters_
        else:
            run_result[s_res] = 1
            iters[s_res] = iters_

        if s_res < best_path_length:
            best_path_length = s_res
            best_path = s  # one of best paths if multiple paths has the same length

    print("time", (time.time() - begin))
    return L, E, best_path_length, best_path, run_result[best_path_length], iters[best_path_length]/run_result[best_path_length]


# TODO check during weekend 15-17.02
def CLK(I, A, K):  # Iterated local search Chained-LK
    # intensification stage: Lin-Kernighan local search
    # diversification stage: double bridge (4-exchange perturbation)

    def hashable_path(path):
        index = np.where(path == 0)[0][0]
        path_ = list(np.roll(path, -index))
        if path_[1] > path_[-1]:
            path_[1: len(path_)] = reversed(path_[1: len(path_)])
        return tuple(path_)

    n = A.shape[0]  # dimensions (number of nodes)
    s = np.random.permutation(n)  # random visiting nodes order
    s_res = path_length(s, A, n)  # path length for order s
    L = {hashable_path(s)}  # set of local optima (estimation generated by sampling)
    E = {}  # escape edges (obtained by double bridge and LK)
    i = 0
    total_iters = 0
    while i < I:
        p = perturbate(s, K)  # K double-bridge operations
        p = intensify(p, A, n)
        p_res = path_length(p, A, n)
        i += 1
        if p_res < s_res:
            L.add(hashable_path(p))  # adding hashable object
            e = (hashable_path(s), hashable_path(p))
            if e in E:
                E[e] += 1
            else:
                E[e] = 1
            s = p
            s_res = p_res
            total_iters += i
            i = 0
    return s_res, s, total_iters, L, E


# TODO check during weekend 15-17.02
def perturbate(nodes_order, K):  # K - kick strength (how many double-bridge operations are applied)
    def double_bridge(path):
        s = np.sort(np.random.choice(path.size, 3, replace=False))  # numpy.random.choice(int, sampleSize, copies?)
        return np.hstack([path[:s[0]], path[s[2]:], path[s[1]:s[2]], path[s[0]:s[1]]])

    nodes_order_ = nodes_order.copy()
    for i in range(K):
        nodes_order_ = double_bridge(nodes_order_)
    return nodes_order_


# TODO check during weekend 15-17.02
def intensify(ind, A, n):  # ind - path, A - matrix, n - dimension
    def improve_path(path):
        g = -np.inf
        best_j = 0
        for j in range(path.size - 1):
            g_ = A[path[j], path[j + 1]] - A[path[j], path[-1]]
            if g_ > g:
                g = g_
                best_j = j
        if g <= 0:
            return None
        return np.hstack([path[:best_j], np.flipud(path[best_j:])])  # TODO ...?

    improvement = True
    ind_score = path_length(ind, A, n)
    while improvement:
        improvement = False
        for i in range(ind.size):
            res = improve_path(ind)
            if res is not None:
                res_score = path_length(res, A, n)
                if res_score < ind_score:
                    ind = res
                    ind_score = res_score
                    improvement = True
                    break
            ind = np.roll(ind, -1)
    return ind


### metrics

def generate_network_metrics(V, E, A, n, performance_metrics):
    best_path_length, best_path, successes, mean_iters = performance_metrics

    nodes = len(V) # number of nodes in LON

    V_ = V.copy()
    for (v1, _) in E.keys():
        if v1 in V_:
            V_.remove(v1)
    sinks = len(V_) # number of sinks in LON

    # TODO modification with incoming degree
    outgoing = adjacency_list(V, E)
    E_ = {} # edge weights
    for v in outgoing.keys():
        edges = 0
        for v_ in outgoing[v]:
            edges += E[(v, v_)]
        for v_ in outgoing[v]:
            E_[(v, v_)] = E[(v, v_)]/edges
    incoming = adjacency_list(V, E, True)
    in_strengths = {}
    for v in V_: # foreach sink - weighted incoming degree
        strength = 0
        for v_ in incoming[v]:
            strength += E_[(v_, v)]
        in_strengths[v] = (path_length(v, A, n), strength)

    optimal_length = math.inf
    optimal_strength = 0
    total_strength = 0
    optimal_sinks = set()
    for v, (length, strength) in in_strengths.items():
        if length < optimal_length:
            optimal_length = length
            optimal_strength = strength
            total_strength += strength
            optimal_sinks = {v}
        if length == optimal_length:
            optimal_strength += strength
            total_strength += strength
            optimal_sinks.add(v)
        else:
            total_strength += strength
    relative_in_strength = optimal_strength/total_strength  # relative in-strength of the globally optimal sink

    S_ = optimal_sinks
    incoming_ = incoming.copy()
    while True:
        S = S_.copy()
        for v in S:
            if v in incoming_.keys():
                for v_ in incoming_[v]:
                    S_.add(v_)
                incoming_.pop(v)
        if len(S) == len(S_):
            break
    nodes_in_optimal_funnels = len(S_)/nodes # proportion of nodes in the globally optimal funnels

    fitnesses = set()
    for v in V:
        fitnesses.add(path_length(v, A, n))
    nodes_with_unique_path_length = len(fitnesses)/nodes # proportion of nodes with unique fitness value (path length)

    return tuple([nodes, sinks, relative_in_strength, nodes_in_optimal_funnels, nodes_with_unique_path_length])


### LON projection !
def project_LON(V, E, A_, n_, nodes_array):  # TODO check
    V_ = set()
    E_1 = {}
    E_2 = {}
    loops = 0
    upstream_edges = 0
    for v in V:
        v_ = tuple([np.where(nodes_array == node)[0][0] for node in v if node in nodes_array])
        if v_ not in V_:
            V_.add(v_)

    for (v1, v2) in E.keys():
        v1_ = tuple([np.where(nodes_array == node)[0][0] for node in v1 if node in nodes_array])
        v2_ = tuple([np.where(nodes_array == node)[0][0] for node in v2 if node in nodes_array])
        if (v1_, v2_) in E_1:
            E_1[(v1_, v2_)] += E[(v1, v2)]
        else:
            E_1[(v1_, v2_)] = E[(v1, v2)]

    for (v1, v2) in E_1.keys():  # E_2 without upstream_edges
        if v1 == v2:  # loop
            loops += 1
        elif path_length(v2, A_, n_) > path_length(v1, A_, n_):
            upstream_edges += 1
        else:
            E_2[(v1, v2)] = E_1[(v1, v2)]

    print('loops', loops, 'upstream edges', upstream_edges)
    return V_, E_1, E_2, loops, upstream_edges


def generate_projection_metrics(L, E, A, n, foldername):
    pass

### helpers

def generate_subinstances(A, n, out_file, amount, nodes_removed):
    for t in range(amount):
        A_, n_, nodes_array = random_subinstance(A, n, n-nodes_removed)
        sub_name = out_file + "_" + str(nodes_removed) + "_" + str(t)
        io.save_TSP(A_, n_, nodes_array, sub_name)


def random_subinstance(A, n, n_):
    picked_v = np.sort(np.random.choice(range(n), n_, replace=False))
    return A[np.array(picked_v)[:,None], np.array(picked_v)], n_, picked_v  # only selected rows & columns




